{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import urllib.request\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>일은 왜 해도 해도 끝이 없을까? 화가 난다.</td>\n",
       "      <td>많이 힘드시겠어요. 주위에 의논할 상대가 있나요?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>이번 달에 또 급여가 깎였어! 물가는 오르는데 월급만 자꾸 깎이니까 너무 화가 나.</td>\n",
       "      <td>급여가 줄어 속상하시겠어요. 월급이 줄어든 것을 어떻게 보완하실 건가요?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>회사에 신입이 들어왔는데 말투가 거슬려. 그런 애를 매일 봐야 한다고 생각하니까 스...</td>\n",
       "      <td>회사 동료 때문에 스트레스를 많이 받는 것 같아요. 문제 해결을 위해 어떤 노력을 ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>직장에서 막내라는 이유로 나에게만 온갖 심부름을 시켜. 일도 많은 데 정말 분하고 ...</td>\n",
       "      <td>관련 없는 심부름을 모두 하게 되어서 노여우시군요. 어떤 것이 상황을 나아질 수 있...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>얼마 전 입사한 신입사원이 나를 무시하는 것 같아서 너무 화가 나.</td>\n",
       "      <td>무시하는 것 같은 태도에 화가 나셨군요. 상대방의 어떤 행동이 그런 감정을 유발하는...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Q  \\\n",
       "0                          일은 왜 해도 해도 끝이 없을까? 화가 난다.   \n",
       "1     이번 달에 또 급여가 깎였어! 물가는 오르는데 월급만 자꾸 깎이니까 너무 화가 나.   \n",
       "2  회사에 신입이 들어왔는데 말투가 거슬려. 그런 애를 매일 봐야 한다고 생각하니까 스...   \n",
       "3  직장에서 막내라는 이유로 나에게만 온갖 심부름을 시켜. 일도 많은 데 정말 분하고 ...   \n",
       "4              얼마 전 입사한 신입사원이 나를 무시하는 것 같아서 너무 화가 나.   \n",
       "\n",
       "                                                   A  label  \n",
       "0                        많이 힘드시겠어요. 주위에 의논할 상대가 있나요?      2  \n",
       "1           급여가 줄어 속상하시겠어요. 월급이 줄어든 것을 어떻게 보완하실 건가요?      2  \n",
       "2  회사 동료 때문에 스트레스를 많이 받는 것 같아요. 문제 해결을 위해 어떤 노력을 ...      2  \n",
       "3  관련 없는 심부름을 모두 하게 되어서 노여우시군요. 어떤 것이 상황을 나아질 수 있...      2  \n",
       "4  무시하는 것 같은 태도에 화가 나셨군요. 상대방의 어떤 행동이 그런 감정을 유발하는...      2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습데이터 (Q:사용자 발화, A:시스템 발화, label:[0:일상, 1:이별(부정), 2:사랑(긍정)])\n",
    "# urllib.request.urlretrieve(\"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv\", filename=\"ChatBotData.csv\")\n",
    "# train_data = pd.read_csv('ChatBotData.csv')\n",
    "# train_data.head()\n",
    "train_data = pd.read_excel('C:/vscode/미니프로젝트/2차프로젝트_챗봇/data/TrainingData2.xlsx')\n",
    "# train_data = train_data.iloc[:,:3]\n",
    "train_data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_excel('C:/vscode/미니프로젝트/2차프로젝트_챗봇/data/TrainingData2.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cfd4228aa524164802d1ea13c4d3137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)6a277/.gitattributes:   0%|          | 0.00/1.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e4a936fce9841469778628eddc60839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_Pooling/config.json:   0%|          | 0.00/191 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f746d4611d41402c97edad0cca0b0083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ccdd26a277/README.md:   0%|          | 0.00/3.79k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7759060e170e494eab1b92f1fd681e4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)dd26a277/config.json:   0%|          | 0.00/746 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcee6e4745904b68bf3d39ed5b0fbc3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ce_transformers.json:   0%|          | 0.00/123 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37aec64150c54e589a3e406dce52b5b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.35G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a84546a75ba541d3bac6f67b3c4efc8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7c5fdf292e9499faa4551e12aa840f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/173 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daae8f8aa040472fa2743390385426f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)6a277/tokenizer.json:   0%|          | 0.00/752k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cfb284846014bde884924362af8fad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/415 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2bbbcda878f432da8802348eca8aea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ccdd26a277/vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab975c7b8b194bb4982d4a6f47c14081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)d26a277/modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 사전학습된 BERT모델 불러오기\n",
    "# model = SentenceTransformer('sentence-transformers/xlm-r-100langs-bert-base-nli-stsb-mean-tokens')\n",
    "# model = SentenceTransformer('jhgan/ko-sroberta-multitask') 이게 제일\n",
    "# model = SentenceTransformer('jhgan/ko-sbert-sts')\n",
    "# model = SentenceTransformer('jhgan/ko-sbert-multitask')\n",
    "# model = SentenceTransformer('ddobokki/klue-roberta-base-nli-sts-ko-en') \n",
    "# 이것도 굿\n",
    "model = SentenceTransformer('yngkyng/klue-roberta-base-sts-ko')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q의 문장 임베딩값 따로 저장\n",
    "train_data['embedding'] = train_data.apply(lambda row: model.encode(row.Q), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tjoeun\\AppData\\Local\\Temp\\ipykernel_6416\\2735008873.py:3: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:248.)\n",
      "  embedding_data = torch.tensor(train_data['embedding'].tolist())\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 tensor로 변환\n",
    "import torch\n",
    "embedding_data = torch.tensor(train_data['embedding'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩 데이터를 pickle 파일로 저장\n",
    "import pickle\n",
    "with open('embedding_data.pickle', 'wb') as file:\n",
    "    pickle.dump(embedding_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두 벡터에서 코사인 유사도 구하는 함수 정의\n",
    "def cos_sim(A, B):\n",
    "    return dot(A, B)/(norm(A)*norm(B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임의의 질문이 들어오면 해당 질문의 문장 임베딩 값과 \n",
    "# 챗봇 데이터의 임베딩 열(train_data['embedding'])에 저장해둔 \n",
    "# 모든 질문 샘플들의 문장 임베딩 값들을 전부 비교하여 \n",
    "# 코사인 유사도 값이 가장 높은 질문 샘플을 찾아내기.\n",
    "# 그리고 해당 질문 샘플과 짝이 되는 답변 샘플을 리턴\n",
    "def return_answer(question):\n",
    "    embedding = model.encode(question)\n",
    "    train_data['score'] = train_data.apply(lambda x: cos_sim(x['embedding'], embedding), axis=1)\n",
    "    # train_data['score'] = train_data.apply(lambda x: cos_sim(embedding_data, embedding), axis=1)\n",
    "    return train_data.loc[train_data['score'].idxmax()]['A']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "여기까지 한 파일로 저장해서 import 해야될듯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'건강에 해로운 건 알지만 인스턴트식품이 너무 맛있어서 계속 먹게 되시는군요.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "# return_answer('요즘 직장생활이 너무 편하고 좋은 것 같아')\n",
    "return_answer('죽고싶지만 떡볶이는 먹고싶어')\n",
    "# return_answer('취업해서 너무 신이 나!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용자 입력값: 결혼한 지 삼 년 만에 아이를 낳았어. 진짜 기뻐\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'간절히 바라던 아이를 출산하셔서 기쁘시군요. 지금 바라는 것이 있으신가요? '"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 입력값 받아서 대답 반환하기\n",
    "human = input('입력하세요')\n",
    "print('사용자 입력값:', human)\n",
    "return_answer(human)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 저장된 임베딩값 파일 따로 불러오는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import util\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전학습된 BERT모델 불러오기\n",
    "model2 = SentenceTransformer('sentence-transformers/xlm-r-100langs-bert-base-nli-stsb-mean-tokens')\n",
    "# model2 = SentenceTransformer('jhgan/ko-sroberta-multitask') \n",
    "# model2 = SentenceTransformer('jhgan/ko-sbert-sts')\n",
    "# model = SentenceTransformer('jhgan/ko-sbert-multitask')\n",
    "model = SentenceTransformer('ddobokki/klue-roberta-base-nli-sts-ko-en') \n",
    "# 이것도 굿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: RobertaModel \n",
       "  (1): Pooling({'word_embedding_dimension': 1024, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model # sts 내가 학습시킨 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 64, 'do_lower_case': False}) with Transformer model: RobertaModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: RobertaModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2\n",
    "# jhgan/ko-sroberta-multitask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2\n",
    "# jhgan/ko-sbert-sts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: XLMRobertaModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2\n",
    "# sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('C:/vscode/미니프로젝트/2차프로젝트_챗봇/data/TrainingData2.xlsx')\n",
    "# Q의 문장 임베딩값 따로 저장\n",
    "df['embedding'] = df.apply(lambda row: model.encode(row.Q), axis = 1)\n",
    "df['embedding2'] = df.apply(lambda row: model2.encode(row.Q), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q의 문장 임베딩값 따로 저장\n",
    "df['embedding2'] = df.apply(lambda row: model2.encode(row.Q), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두 벡터에서 코사인 유사도 구하는 함수 정의\n",
    "def cos_sim(A, B):\n",
    "    return dot(A, B)/(norm(A)*norm(B))\n",
    "\n",
    "def return_answer(question):\n",
    "    embedding = model.encode(question)\n",
    "    df['score'] = df.apply(lambda x: cos_sim(x['embedding'], embedding), axis=1)\n",
    "    return df.loc[df['score'].idxmax()]['A']\n",
    "\n",
    "def return_answer2(question):\n",
    "    embedding = model2.encode(question)\n",
    "    df['score2'] = df.apply(lambda x: cos_sim(x['embedding2'], embedding), axis=1)\n",
    "    return df.loc[df['score2'].idxmax()]['A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "공부가 잘 된다니 정말 좋으시겠어요. 특별한 이유가 있나요?\n",
      "죽고 싶다는 극단적인 생각을 하시게 된 이유가 있나요? 무슨일이신지 말씀해주세요.\n",
      "회사 생활이 무척 피곤하시군요.\n",
      "친구와 어떤 일이 있으셨던 건가요? 저에게 알려주실 수 있나요?\n",
      "공부법을 찾아 기분이 좋으신가 봐요. 공부법이 마음에 드나요?\n",
      "남편과의 사별로 많이 슬프시겠어요.\n",
      "아픈 몸으로 일하시느라 고생이 많으세요. \n",
      "시트에 커피를 쏟으셨다니 정말 화나시겠어요.\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "test = [\n",
    "    '요즘 공부가 잘되어서 기분이 좋아',\n",
    "    '죽고싶지만 떡볶이는 먹고싶어',\n",
    "    '일하는 중인데 너무 졸려서 집에 가고싶어',\n",
    "    '친구가 커피에 고추가루를 넣어먹는데 대체 왜 그러는지 정말 당황스러워.'\n",
    "]\n",
    "\n",
    "for i in test:\n",
    "    print(return_answer(i))\n",
    "for i in test:\n",
    "    print(return_answer2(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def return_sim_question(input_sentence):\n",
    "#     input_sentence = model.encode(input_sentence)\n",
    "#     input_sentence = torch.tensor(input_sentence)\n",
    "#     return input_sentence\n",
    "\n",
    "# def chatbot(message):\n",
    "#     message = message.strip()\n",
    "#     # 입력 문장 임베딩\n",
    "#     embedding_sentence = return_sim_question(message)\n",
    "\n",
    "#     # 미리 구해진 임베딩 데이터와 현재 임베딩 데이터의 코사인 유사도 추출\n",
    "#     cos_sim = util.pytorch_cos_sim(embedding_sentence,embedding_data)\n",
    "#     # cos_sim = cos_sim.cpu()\n",
    "\n",
    "#     #유사도가 가장 비슷한 질문 인덱스 반환\n",
    "#     best_sim_idx = int(np.argmax(cos_sim))\n",
    "\n",
    "#     #유사도가 가장 비슷한 질문에 해당하는 답변 제공\n",
    "#     answer = df['A'][best_sim_idx]\n",
    "#     return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_excel('C:/vscode/미니프로젝트/2차프로젝트_챗봇/data/TrainingData2.xlsx')\n",
    "\n",
    "# # pickle 파일에서 데이터 로드\n",
    "# import pickle\n",
    "# with open('embedding_data.pickle', 'rb') as file:\n",
    "#     embedding_data = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용자 입력값: 죽고싶지만 떡볶이는 먹고싶어\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'죽고 싶다는 극단적인 생각을 하시게 된 이유가 있나요? 무슨일이신지 말씀해주세요.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# human = input('입력하세요')\n",
    "\n",
    "# print('사용자 입력값:', human)\n",
    "# #return_answer(human)\n",
    "# chatbot(human)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
